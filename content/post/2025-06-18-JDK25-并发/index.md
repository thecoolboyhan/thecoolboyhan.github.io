---
title: 备战JDK25--并发
description: JDK25今年年底就要发布了，这次深入了解结构化并发和各种并发框架，争取一起搞清后面几年的并发
slug: JDK25-1
date: 2025-06-18 00:00:00+0000
image: 1.png
categories:
    - java
    - 精选
tags: 
    - java
    - 多线程
    - 结构化并发
    - 并发
---



## 并发集合



### Queue（七个默认的并发用队列）



1. **ArrayBlockingQueue**

- **实现原理**：   基于循环数组实现的有界阻塞队列。内部使用单一的 `ReentrantLock` 来保证线程安全，支持可选的公平（fair）策略。
- **特性**：
  - **有界性**：队列容量在创建时就确定好，不能动态扩充。
  - **FIFO 顺序**：遵循先进先出规则。
  - **阻塞策略**：当队列满时调用 `put()` 会阻塞；当队列空时调用 `take()` 会阻塞。
- **应用场景**：   在需要严格控制资源使用、限制任务数量的生产者—消费者场景中非常合适。例如线程池中，希望通过固定大小队列来防止任务积压导致内存溢出。



2. **LinkedBlockingQueue**

- **实现原理**：   基于链表实现的阻塞队列。在没有显式设置容量时，其默认容量为 `Integer.MAX_VALUE`（即近似无界），可以通过构造函数指定上限。内部采用两个锁——一个用于插入（putLock），另一个用于移除（takeLock），从而在高并发场景下能有效分离生产者和消费者的互斥操作。
- **特性**：
  - **可定界**：既可以指定队列大小，也可以使用默认无界。
  - **FIFO 顺序**：严格的先进先出。
  - **阻塞策略**：与 ArrayBlockingQueue 类似，队列满时插入阻塞，队列空时移除阻塞。
- **应用场景**：   常用于多生产者、多消费者的线程池任务队列，尤其是在任务生产与消费速度不一的场景中可帮助平衡负载。



3. **PriorityBlockingQueue**

- **实现原理**：   基于堆（通常是最小堆）实现的无界阻塞队列，队列中的元素需要实现 `Comparable` 接口或通过提供 `Comparator` 进行排序。
- **特性**：
  - **无界**：通常不设置容量上限，因此入队操作（`offer`/`put`）永远不会阻塞。
  - **排序策略**：队列中的元素顺序不是简单的 FIFO，而是按照优先级（自然顺序或比较器顺序）排序。
  - **阻塞策略**：当队列为空时，`take()` 操作会阻塞；但由于队列无界，入队操作不会因为容量问题而阻塞。
- **应用场景**：   当需要按照任务优先级而非提交顺序来处理任务时，例如任务调度系统、事件处理系统等场景。



4. **DelayQueue**

- **实现原理**：   是一个特殊的无界阻塞队列，队列中所有元素必须实现 `Delayed` 接口。内部同样基于堆结构来维护元素顺序，但只有当元素所关联的延迟时间到期后才能从队列中取出。
- **特性**：
  - **时间控制**：每个元素都带有一个延时，只有延时到期才能被消费。
  - **无界**：同 PriorityBlockingQueue，其入队操作不会阻塞。
  - **阻塞策略**：若队列头部元素延时未到，`take()` 将阻塞等待。
- **应用场景**：   非常适合实现定时任务调度、延时消息处理、缓存失效机制等需要时间延迟控制的场景。



5. **SynchronousQueue**

- **实现原理**：   与其他队列不同，SynchronousQueue 没有任何内部容量，每个插入操作都必须等待一个相对应的移除操作。它实际上充当一个手递手（handoff）的桥梁。
- **特性**：
  - **无容量**：不能存储元素，所有操作都是直接交互。
  - **阻塞策略**：无论是 `put()` 还是 `take()` 都会因为没有对方而阻塞，直到另一个操作到达。
  - **公平/非公平模式**：可以通过构造函数选择公平模式，从而影响线程获得等待权的顺序。
- **应用场景**：   通常用于线程池中作为工作线程直接传递任务的机制，减少任务在队列中积压，实现更低延迟的任务“交接”。



6. **LinkedTransferQueue**

- **实现原理**：   基于链表的无界队列，实现了 `TransferQueue` 接口，扩展了阻塞队列的功能。除了普通的入队/出队操作之外，它还提供了 `transfer()` 方法，允许生产者等待直到有消费者接收该元素。
- **特性**：
  - **无界**：不限制容量。
  - **直接交付选项**：通过 `transfer()` 或 `tryTransfer()` 方法，可实现任务的立即交付。
  - **高并发设计**：适合于需要低延迟和高吞吐量的任务传递场景。
- **应用场景**：   它适用于任务即交付（即若有消费者等待则直接传递，否则则存入队列等待）的场景，常见于高性能消息传递和任务调度系统中。



7. **ConcurrentLinkedQueue**

- **实现原理**：   虽然不属于阻塞队列，但它是一个基于非阻塞算法（CAS）的无界线程安全队列。内部使用链表数据结构，但不提供阻塞机制。
- **特性**：
  - **无界且非阻塞**：消费者需要主动轮询，没有内部锁或阻塞机制。
  - **高效**：在高并发场景下表现优异，但要求消费者能容忍轮询方式带来的延迟。
- **应用场景**：   当你只需要一个安全的队列而不希望引入因阻塞带来的额外开销时，用于日志缓冲、任务缓存等场景较为合适。



#### **总结**

| 队列类型                  | 是否有界 | 内部数据结构 | 顺序策略       | 阻塞行为                                               | 典型应用场景                           |
| ------------------------- | -------- | ------------ | -------------- | ------------------------------------------------------ | -------------------------------------- |
| **ArrayBlockingQueue**    | 有界     | 数组         | FIFO           | 队列满阻塞入队，空阻塞出队                             | 固定任务数量的生产者消费者模型         |
| **LinkedBlockingQueue**   | 可定界   | 链表         | FIFO           | 满时阻塞入队，空时阻塞出队                             | 线程池任务队列，多生产者多消费者       |
| **PriorityBlockingQueue** | 无界     | 堆           | 按优先级排序   | 空阻塞出队，不因容量问题阻塞入队                       | 优先级任务调度                         |
| **DelayQueue**            | 无界     | 堆           | 按延迟时间排序 | 头部未到期阻塞出队，入队不阻塞                         | 定时任务、延时消息、缓存失效机制       |
| **SynchronousQueue**      | 无容量   | 无内部存储   | 直接交接       | 生产者与消费者相互等待，双方都可能阻塞                 | 任务直接交付（如线程池任务传递）       |
| **LinkedTransferQueue**   | 无界     | 链表         | FIFO           | 支持通过 `transfer()` 进行直接交付，也支持常规阻塞操作 | 高性能、低延迟的任务传递               |
| **ConcurrentLinkedQueue** | 无界     | 链表         | 逻辑FIFO       | 非阻塞，需主动轮询消费                                 | 非阻塞场景，如日志消息队列、临时缓冲区 |



#### 如何选择



- **内存和容量控制**：如果希望严格限制内存或任务数量，选择有界的队列（如 ArrayBlockingQueue 或定界的 LinkedBlockingQueue）。
- **任务顺序**：需要按提交顺序处理任务时，FIFO 队列（ArrayBlockingQueue、LinkedBlockingQueue）较为理想；而需要基于状态优先级排序时，则应选 PriorityBlockingQueue。
- **时间调度**：如果任务需要延迟处理，则 DelayQueue 能够根据时间精确控制任务释放。
- **直接交接场景**：任务需要立即转交给消费者，避免积压则可以使用 SynchronousQueue 或 LinkedTransferQueue，它们能实现生产者和消费者之间的直接交付。
- **并发性能非阻塞场景**：当阻塞不是必需的，而仅需提供线程安全的队列操作时，ConcurrentLinkedQueue 是个好选择。



### Map

#### ConcurrentHashMap

传统拉链法hashMap结构，相比hashMap，线程安全采用hash格位上锁synchronized。内部put元素采用cas操作。多线程操作同一个元素，如果出现扩容，会多线程辅助扩容。扩容期间采用地址转发的方式来保证每个请求都能取到对象。



- 数据结构

**JDK7之前**

采用分段机制，每个段都是独立的HashMap。每个段采用独立的锁来保证线程安全。

**JDK8之后**

取消了分段机制，结构完全类似于hashMap，采用Node数组来存放hash头，每个node元素单独synchronized上锁





- 并发扩容

不再由单个线程来完成扩容操作。

而是多个线程共同参与。扩容过程中，如果有线程去原位置获取元素，会创建临时的地址转发保证正确的获取元素。



- 无锁get操作

get方法依赖于volatile来保证元素内存的可见性。能够在JVM层面不上锁的方式来读取对象



#### ConcurrentSkipListMap

并发有序MAP



- 数据结构（跳表）



主要有两层结构

1. 底层链表（Base List）：存储所有键值对节点，按顺序构成单向链表称为底层。
2. 索引层（Index Levels）：在底层之上，建立多级索引（塔），每一层索引节点通过指针连接，构成稀疏的链表，加快查找过程。



> 查找、插入、删除平均时间复杂度都为O(log n)



``` xml
 高层:     HeadIndex -> Index -> Index -> null
                 |          |
 中间层:     Index ------> Index ------> null
                 |          |
 底层:        Node  -->  Node  -->  Node  --> null

```



- 查

查询时从HeadIndex出发，向右查找，遇到比目标大的键就下一层，直到到达最底层。



- 插入

> 插入主要分两个部分，首先需要在底层链表中插入元素，其次就是有可能会提升出一个新的索引

1. 底层插入：利用CAS在底层链表插入新的节点，保证有序性。
2. 随机提升：利用随机判断，有几率让新插入的值向上升级，做索引键
3. 更新索引层：如果需要提升层数（层数可能不固定），在上层建立新的index节点，更新right、down指针。

时间复杂度：O(log n)



- **如何保证并发？**



1. **无锁并发读取**：大部分查找操作都是无锁的，内部节点通过volatile修饰来保证可见性
2. **小颗粒度的锁加CAS写操作**：插入、删除时，仅对局部结构上锁和利用CAS操作保证数据一致性（只存在较少的阻塞操作）
3. 弱一致性迭代器：通过迭代器遍历过程中允许并发更新，不会有并发修改异常。



### List

#### CopyOnWriteArrayList

> 写时复制，可以避免快速失败。

- 写时复制（同时只能有一个线程来修改数组）

添加、删除和更新操作，会先复制一份内部数组（Arrays.copyOf），对新复制的副本来进行修改。通过volatile来保证内部引用可见性。

- 无锁读取

写时产生的新数组会替换旧数组，每次读取时都只读取内部数组（内部数组被Volatile修饰），从而保证可见性和有序性



