---
title:  读《凤凰架构》有感
description: 最近攻读周志明老师的《凤凰架构》，书中介绍了软件领域的架构演进，涉及到众多架构知识，分布式场景的设计原则等，不知能否做到归纳总结。
image: 1.png
date: 2025-08-07
slug: icyfenix
categories: 
  - 精选
  - 分布式
  - 架构
tags:
  - 分布式
  - 读后感
  - 架构
---



# 凤凰架构

> 文中大部分资料摘抄自周志明老师的[凤凰架构](https://icyfenix.cn/)开源网站



## 服务架构演进史

> 本部分介绍了架构的演进，并详细讲解了凤凰架构的概念，由于内容众多，且难以总结。后续详细补充。





## 架构

### 访问远程服务



#### 远程服务调用（RPC）



> RPC出现的目的是为了让计算机能够跟调用本地方法一样去调用远程方法。







##### **进程间通讯（IPC）**



1. 管道（pipe）

   管道类似于两个进程间的桥梁，可以通过管道在进程间传递少量的字符流或字节流。

   管道命令：

   ``` sh
   ps -ef | grep java
   ```

2. 信号（Signal）

   用于通知目标某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程自身。

   信号命令：

   ``` sh
   kill -9 pid
   ```

3. 信号量（Semaphore)

   两个进程之间同步协作的手段，相同于操作系统提供的一个特殊变量，程序可以在上面进行wait（）和notify（）操作。

4. 消息队列（Message Queue）：上面的三个方式只适合传递少量信息，消息队列用于进程间数据量较多的通信。

5. 共享内存（Shared Memory）：允许多个进程访问同一块公共的内存空间，这是效率最高的进程间通信方式。

6. 套接字接口（Socket）：可用于不同机器之间的进程通信。



![img](https://icyfenix.cn/assets/img/rpc.38c28315.png)





#####  RPC的三个基本问题



- 如何表示数据（序列化与反序列化）

将交互双方锁涉及的数据转换为某种事先约定好的中立数据流格式来进行传输，将输数据流转换回不同语言中对应的数据类型来进行使用。





- 如何传递数据

两个服务的Endpoint之间交互操作、交换数据。一般是基于标准的TCP、UDP等标准的传输层协议来完成的。（也有可能直接使用HTTP协议来实现）



- 如何确定方法

编译器或者解释器回根据语言规范，将调用的方法签名传唤为进程空间中子过程入口位置的指针。





#### REST设计风格（表征状态转移）



> 并非协议，只是一种风格
>
> RPC：面向过程编程
> REST：面向资源编程







- 资源（Resource）：内容本身，如信息、数据等。远程调用等都是为了提供资源。
- 表征（Representation）：信息与用户交互时的表示形式，这与软件分层架构中常说的表示层的语义一致。
- 状态（State）：分成有状态与无状态，由服务端保存用户目前所处的阶段或状态为有状态，由用户自己保存自己目前所处的状态，服务端只负责提供资源的为无状态。
- 转移（Transfer）：服务端通过某种方式让用户的状态发生改变，如获取了新资源等。这个操作被称为：表征状态转移





##### REST风格的六大原则



1. 服务端与客户端分离（Client-Server）前后端分离

   将用户界面所关注的逻辑和数据存储所关注的逻辑分离开来，有助于提高用户界面的跨平台的可移植性。

2. 无状态（Stateless）去除session

   REST希望服务器不要去负责维护状态，每一次从客户端发送的请求中，应包括所有必要的上下文信息，会话信息也由客户端负责保存维护，服务端依据客户端传递的状态来执行业务处理逻辑，驱动整个应用的状态变迁。

   > 目前大部分系统达不到这个要求，服务端无状态可以在分布式计算中获得非常高的价值，但即希望于用户每次传输大量的上下文有点不切实际。

3. 可缓存（Cacheability）分布式缓存

   无状态服务器虽然提升了系统的可见性、可靠性和可伸缩性，但降低了系统的网络性。REST希望分布式系统有一个可以暂时缓存数据的分布式缓存（Redis），这样服务器直接交互，可以进一步提高性能。

4. 分层系统（Layered System）（负载均衡）

   客户端不需要直到是否直接连接到了最终的服务器，中间服务器可以通过负载均衡和共享缓存的机制提高系统的可扩展性，这样便于缓存、伸缩和安全策略的部署。

5. 统一接口（Uniform Interface）（面向资源）

   REST希望开发者面向资源编程，希望软件系统设计的重点放在抽象系统该有哪些资源上，而不是抽象系统该有哪些行为（服务）上。

   用一个登录场景来举例子：

   传统思维：登录login()服务，注销logout（）服务。

   REST思维：登录，PUT Session，注销DELETE Session。查询登录信息，GET Session

   > 所有的资源最好应该是自描述信息的，或都是通过资源id来进行的。

6. 按需代码（Code-On-Demand）（可选项）

   客户端无需直到服务端如何运行，服务端会按需把需要的可执行程序发送给客户端执行。









##### RMM成熟度

> 如何衡量一个服务有多么REST，下面直接引入书中的内容





0. 完全不REST

   医院开放了一个`/appointmentService`的 Web API，传入日期、医生姓名作为参数，可以得到该时间段该名医生的空闲时间，该 API 的一次 HTTP 调用如下所示：

   ```http
   POST /appointmentService?action=query HTTP/1.1
   
   {date: "2020-03-04", doctor: "mjones"}
   ```

   然后服务器会传回一个包含了所需信息的回应：

   ```http
   HTTP/1.1 200 OK
   
   [
   	{start:"14:00", end: "14:50", doctor: "mjones"},
   	{start:"16:00", end: "16:50", doctor: "mjones"}
   ]
   ```

   得到了医生空闲的结果后，我觉得 14:00 的时间比较合适，于是进行预约确认，并提交了我的基本信息：

   ```http
   POST /appointmentService?action=confirm HTTP/1.1
   
   {
   	appointment: {date: "2020-03-04", start:"14:00", doctor: "mjones"},
   	patient: {name: icyfenix, age: 30, ……}
   }
   ```

   如果预约成功，那我能够收到一个预约成功的响应：

   ```http
   HTTP/1.1 200 OK
   
   {
   	code: 0,
   	message: "Successful confirmation of appointment"
   }
   ```

   如果发生了问题，譬如有人在我前面抢先预约了，那么我会在响应中收到某种错误信息：

   ```http
   HTTP/1.1 200 OK
   
   {
   	code: 1
   	message: "doctor not available"
   }
   ```

   到此，整个预约服务宣告完成，直接明了，我们采用的是非常直观的基于 RPC 风格的服务设计似乎很容易就解决了所有问题……了吗？

1. Resource：开始引入资源的概念

   第 0 级是 RPC 的风格，如果需求永远不会变化，也不会增加，那它完全可以良好地工作下去。但是，如果你不想为预约医生之外的其他操作、为获取空闲时间之外的其他信息去编写额外的方法，或者改动现有方法的接口，那还是应该考虑一下如何使用 REST 来抽象资源。

   通往 REST 的第一步是引入资源的概念，在 API 中基本的体现是围绕着资源而不是过程来设计服务，说的直白一点，可以理解为服务的 Endpoint 应该是一个名词而不是动词。此外，每次请求中都应包含资源的 ID，所有操作均通过资源 ID 来进行，譬如，获取医生指定时间的空闲档期：

   ```http
   POST /doctors/mjones HTTP/1.1
   
   {date: "2020-03-04"}
   ```

   然后服务器传回一组包含了 ID 信息的档期清单，注意，ID 是资源的唯一编号，有 ID 即代表“医生的档期”被视为一种资源：

   ```http
   HTTP/1.1 200 OK
   
   [
   	{id: 1234, start:"14:00", end: "14:50", doctor: "mjones"},
   	{id: 5678, start:"16:00", end: "16:50", doctor: "mjones"}
   ]
   ```

   我还是觉得 14:00 的时间比较合适，于是又进行预约确认，并提交了我的基本信息：

   ```http
   POST /schedules/1234 HTTP/1.1
   
   {name: icyfenix, age: 30, ……}
   ```

   后面预约成功或者失败的响应消息在这个级别里面与之前一致，就不重复了。比起第 0 级，第 1 级的特征是引入了资源，通过资源 ID 作为主要线索与服务交互，但第 1 级至少还有三个问题并没有解决：一是只处理了查询和预约，如果我临时想换个时间，要调整预约，或者我的病忽然好了，想删除预约，这都需要提供新的服务接口。二是处理结果响应时，只能靠着结果中的`code`、`message`这些字段做分支判断，每一套服务都要设计可能发生错误的 code，这很难考虑全面，而且也不利于对某些通用的错误做统一处理；三是并没有考虑认证授权等安全方面的内容，譬如要求只有登陆用户才允许查询医生档期时间，某些医生可能只对 VIP 开放，需要特定级别的病人才能预约，等等。

2. HTTP Verbs：引入统一接口，映射到HTTP协议

   第 1 级遗留三个问题都可以靠引入统一接口来解决。HTTP 协议的七个标准方法是经过精心设计的，只要架构师的抽象能力够用，它们几乎能涵盖资源可能遇到的所有操作场景。REST 的做法是把不同业务需求抽象为对资源的增加、修改、删除等操作来解决第一个问题；使用 HTTP 协议的 Status Code，可以涵盖大多数资源操作可能出现的异常，而且 Status Code 可以自定义扩展，以此解决第二个问题；依靠 HTTP Header 中携带的额外认证、授权信息来解决第三个问题，这个在实战中并没有体现，请参考安全架构中的“[凭证](https://icyfenix.cn/architect-perspective/general-architecture/system-security/credentials)”相关内容。

   按这个思路，获取医生档期，应采用具有查询语义的 GET 操作进行：

   ```http
   GET /doctors/mjones/schedule?date=2020-03-04&status=open HTTP/1.1
   ```

   然后服务器会传回一个包含了所需信息的回应：

   ```http
   HTTP/1.1 200 OK
   
   [
   	{id: 1234, start:"14:00", end: "14:50", doctor: "mjones"},
   	{id: 5678, start:"16:00", end: "16:50", doctor: "mjones"}
   ]
   ```

   我仍然觉得 14:00 的时间比较合适，于是又进行预约确认，并提交了我的基本信息，用以创建预约，这是符合 POST 的语义的：

   ```http
   POST /schedules/1234 HTTP/1.1
   
   {name: icyfenix, age: 30, ……}
   ```

   如果预约成功，那我能够收到一个预约成功的响应：

   ```http
   HTTP/1.1 201 Created
   
   Successful confirmation of appointment
   ```

   如果发生了问题，譬如有人在我前面抢先预约了，那么我会在响应中收到某种错误信息：

   ```http
   HTTP/1.1 409 Conflict
   
   doctor not available
   ```

3. 超文本驱动的REST接口

第 2 级是目前绝大多数系统所到达的 REST 级别，但仍不是完美的，至少还存在一个问题：你是如何知道预约 mjones 医生的档期是需要访问`/schedules/1234`这个服务 Endpoint 的？也许你甚至第一时间无法理解为何我会有这样的疑问，这当然是程序代码写的呀！但 REST 并不认同这种已烙在程序员脑海中许久的想法。RMM 中的 Hypermedia Controls、Fielding 论文中的 HATEOAS 和现在提的比较多的“超文本驱动”，所希望的是除了第一个请求是由你在浏览器地址栏输入所驱动之外，其他的请求都应该能够自己描述清楚后续可能发生的状态转移，由超文本自身来驱动。所以，当你输入了查询的指令之后：

```http
GET /doctors/mjones/schedule?date=2020-03-04&status=open HTTP/1.1
```

服务器传回的响应信息应该包括诸如如何预约档期、如何了解医生信息等可能的后续操作：

```http
HTTP/1.1 200 OK

{
	schedules：[
		{
			id: 1234, start:"14:00", end: "14:50", doctor: "mjones",
			links: [
				{rel: "comfirm schedule", href: "/schedules/1234"}
			]
		},
		{
			id: 5678, start:"16:00", end: "16:50", doctor: "mjones",
			links: [
				{rel: "comfirm schedule", href: "/schedules/5678"}
			]
		}
	],
	links: [
		{rel: "doctor info", href: "/doctors/mjones/info"}
	]
}
```

如果做到了第 3 级 REST，那服务端的 API 和客户端也是完全解耦的，你要调整服务数量，或者同一个服务做 API 升级将会变得非常简单。





> 备注：个人认为这样开发过于夸张，但不可否认，通过动态的返回可选的url，可以强大的实现权限控制，功能扩展等。







##### REST的不足



1. 面向资源编程只适合CRUD，面向过程、面向对象编程才能处理真正复杂的业务
2. REST和HTTP完全绑定，不适合应用于要求高性能传输的场景
3. REST不利于事务支持
4. REST没有传输可靠性支持
5. REST缺乏对资源进行“部分”和“批量”的处理能力





### 事务处理



- 事务的ACID

C：一致性，一致性不是维持事务的手段，而是我们需要达到的目的。如果保证事务的一致性，只有完成了其他三种手段，才能保证事务的一致性。

下面是源文的原话：

> A、I、D 是手段，C 是目的，前者是因，后者是果，弄到一块去完全是为了拼凑个单词缩写。



A原子性：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。

I隔离性：在不同的业务处理过程中，事务保证了各自业务正在读写的数据互相独立，不会彼此影响。

D持久性：事务应当保证所有成功被提交的数据修改都能正确地被持久化，不丢数据。







- 内部一致性

一个服务只使用了一个数据源时，通过AID来保证一致性。



- 外部一致性

一个服务使用多个不同的数据源，甚至多个服务同时涉及多个不同的数据源。







#### 本地事务（局部事务）

> 仅操作单一事务资源的、不需要全局事务管理器进行协调的事务。





- 原子性和持久性

> 原子性：要么都生效，要么都不生效，不存在中间状态。
>
> 持久性：一旦事务生效，就不会再因为任务原因而导致其修改的内容被撤销或丢失。



- 原子性：

**未提交事务，写入后崩溃**：如果修改进行了一部分，但事务没有提交程序就崩溃了。程序一旦重启，数据库必须要有办法得知崩溃前发生过一次不完整的购物操作，将已经修改过的数据从磁盘中恢复成没有修改过的样子。保证原子性。



> mysql的做法：通过MVCC，事务在修改时，会先生成对应的undolog版本链，达到记录每次状态的目的。如果遇到上述情况，可以通过版本链来选择需要恢复的版本。（实现事务的回滚操作）



- 持久性：

**已提交事务，写入前崩溃**：程序已经完成了修改，提交了事务，但还没有把修改后的结果都写入到磁盘中，此时出现了崩溃。程序一旦重启后，数据库必须要有办法得知崩溃前发生过一次完整的操作，将没来得及写入磁盘的部分重新写入磁盘，保证持久性。



> mysql的做法：通过redo log，事务提交前必须保证redo log已写入完毕，就算事务提交但数据没有落盘。也可以保证在重启时通过redo log来加载到修改的变量。
> 同时redolog也缩小了刷盘的次数和每次需要修改更新的数据量，不需要一次性读取更新整页的数据。减少了成本



以日志的形式——即仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。只有在日志记录全部都安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化，这种事务实现方法被称为“Commit Logging”（提交日志）。





- 另一种保证持久性和原子性的方式**Shadow Paging**

对数据的变动会写到硬盘的数据中，但并不是直接就地修改原先的数据，而是先将数据复制一份副本，保留原数据，修改副本数据。

当事务成功提交，所有数据的修改都成功持久化之后，最后一步是去修改数据的引用指针，将引用从原数据改为新复制出来修改后的副本，最后的“修改指针”这个操作将被认为是原子操作，现代磁盘的写操作可以认为在硬件上保证了不会出现“改了半个值”的现象。所以 Shadow Paging 也可以保证原子性和持久性。



> 以上方式和copyonwritelist的实现非常像。





- FORCE：当事务提交后，要求变动数据必须同时完成写入则称为FORCE，不强制要求同时写入为NO-FORCE。
- STEAL：事务提交前，允许变动数据提前写入则称为STEAL，不允许则称为NO-STEAL。

> 下图中，左边为磁盘IO性能考虑，右边为想要达到效果需要用到的日志。







![1754632791295.png](https://fastly.jsdelivr.net/gh/thecoolboyhan/th_blogs@main/image/2025-08/1754632791295_1754632791314.png)







- 隔离性

>  保证每个事务各自读、写的数据相互独立，不会彼此影响。

这里只突出讲解不同隔离级别下是否需要锁和对应的上锁范围，并不突出mysql的锁。如果想详细了解mysql的锁，可以看我的[这篇文章](https://thecoolboyhan.github.io/p/mysql-lock/)。



> 现代数据库提供的三种锁：



1. 写锁（X锁）：只有持有写锁的数据才能对数据进行写入操作，数据被加写锁时，其他事务不能写入数据，也不能施加读锁。

2. 读锁（S锁）：多个事务对同一个数据加多个读锁，只要数据上还有读锁，就不能再加写锁，其他事务也不能对该数据进行写入，但仍然可以读取。如果数据只有当前事务自己添加了读锁，可以把读锁升级成写锁，然后写入数据。

3. 范围锁：对与某个范围上锁，实现多种多样。在这个范围内的数据不能被写入。

   > ```sql
   > SELECT * FROM books WHERE price < 100 FOR UPDATE;
   > ```
   >
   > 



- 隔离性的差异





1. 串行化：同一时间只能存在一个事务，其他事务需要等待当前事务执行后才能开启。

   天生具有隔离性，不需对数据加任何锁。但性能极差，没有并发能力。

2. 可重复读（RR）：只对事务所涉及到的数据加读锁或者写锁，且一直持有锁到事务结束。但任可能产生[幻读问题](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Phantom_reads)。事务在执行过程中，两个完全相同的范围查询得到的结果集不一致。

   ``` mysql
   SELECT count(1) FROM books WHERE price < 100					/* 时间顺序：1，事务： T1 */
   INSERT INTO books(name,price) VALUES ('深入理解Java虚拟机',90)	/* 时间顺序：2，事务： T2 */
   SELECT count(1) FROM books WHERE price < 100					/* 时间顺序：3，事务： T1 */
   ```

   可重复读没有范围锁来禁止对该范围内插入新的数据，导致隔离性被破坏。

   >  mysql在可重复读级别下，只读事务完全可以避免幻读问题。但在读写事务下，依然可能出现幻读问题。（MVCC并不能完美解决幻读）
   >
   > 如：事务 T1 如果在其他事务插入新书后，不是重新查询一次数量，而是要将所有小于 100 元的书改名，那就依然会受到新插入书籍的影响。

3. 读已提交（RC）：写锁会一直持续到事务结束，但读锁会在每次查询操作结束后就会立刻释放。会产生[不可重复读问题](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Non-repeatable_reads)。同一行数据的两次查询得到了不同的结果。

   读已提交缺乏整个周期性的读锁，无法禁止读取过的数据发生变化。隔离性被破坏的表现。

4. 读未提交（RU）：对事务涉及的数据只加写锁一直持续到事务结束，但完全不加读锁。会产生[脏读问题](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Dirty_reads)。一个事务读取到另一个事务未提交的数据。

> 理论还存在更低的隔离性，就是事务既不加读锁，也不加写锁。



<font color='red'>**不同隔离级别产生的问题只是表面现象，是各种锁在不同加锁时间上组合而产生的结果，以锁为手段来实现隔离性才是数据库表现出不同隔离级别的根本原因。**</font>





- MVCC（只针对读+写场景）

- 插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。
- 删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。
- 修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。

此时，如有另外一个事务要读取这些发生了变化的数据，将根据隔离级别来决定到底应该读取哪个版本的数据。

- 隔离级别是`可重复读`：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。
- 隔离级别是`读已提交`：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。

另外两个隔离级别都没有必要用到 MVCC，因为`读未提交`直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。`可串行化`本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。



> mysql利用undolog和锁来实现MVCC









#### 全局事务（外部事务）

> 单个服务使用多个数据源场景的事务解决方案。

全局事务和本地事务代码表现得不同：

``` java
public void buyBook(PaymentBill bill) {
    userTransaction.begin();
    warehouseTransaction.begin();
    businessTransaction.begin();
	try {
        userAccountService.pay(bill.getMoney());
        warehouseService.deliver(bill.getItems());
        businessAccountService.receipt(bill.getMoney());
        userTransaction.commit();
        warehouseTransaction.commit();
        businessTransaction.commit();
	} catch(Exception e) {
        userTransaction.rollback();
        warehouseTransaction.rollback();
        businessTransaction.rollback();
	}
}
```

开启三个事务，提交三个事务，或回滚三个事务。保证多个事务要么全部成功，要么全部失败。







- 2PC协议

1. 准备阶段：投票阶段，协调者询问事务的所有参与者是否准备好提交。
2. 提交阶段：执行阶段，协调者如果在上一个阶段收到所有事务参与者回复的可提交消息，则先自己在本地持久化事务为commit状态，然后给所有参与者发送commit指令。所有参与者立刻执行提交操作。



<mermaid style="margin-bottom: 0px"> 

sequenceDiagram
	协调者 ->>+ 参与者: 要求所有参与者进入准备阶段
	参与者 -->>- 协调者: 已进入准备阶段
	协调者 ->>+ 参与者: 要求所有参与者进入提交阶段
	参与者 -->>- 协调者: 已进入提交阶段
    opt 失败或超时
        协调者 ->>+ 参与者: 要求所有参与者回滚事务
        参与者 -->>- 协调者: 已回滚事务
    end
</mermaid>

:::center
图 3-1 两段式提交的交互时序示意图
:::

![1754644931270.png](https://fastly.jsdelivr.net/gh/thecoolboyhan/th_blogs@main/image/2025-08/1754644931270_1754644931355.png)





**2PC能够保证一致性的前提条件**：



1. 网络在提交阶段必须是可靠的，不能在提交阶段丢失消息。如果投票阶段失败还可以执行回滚操作，但如果提交阶段失败就无法补救。
2. 必须假设在网络分区、机器崩溃或者其他原因导致的节点失联最终能够回复，不会永久性地失联。



**2PC的缺点**：



1. 单点问题：协调者在两阶段提交中具有举足轻重的作用，协调者在等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。

   如果协调者宕机，就没法正常发送Commit或者RollBack指令，所有参与者都必须一直等待。

2. 性能问题：所有参与者都相当于绑定成一个统一调度的整体，期间要经过两次远程服务调用，三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入 Commit Record）。必须等待执行最慢的参与者执行完毕后，才算事务提交，所以性能较差。

3. 一致性风险：尽管提交阶段时间很短，但这仍是一段明确存在的危险期，如果协调者在发出准备指令后，根据收到各个参与者发回的信息确定事务状态是可以提交的，协调者会先持久化事务状态，并提交自己的事务，如果这时候网络忽然被断开，无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部分数据（协调者的）已提交，但部分数据（参与者的）既未提交，也没有办法回滚，产生了数据不一致的问题。

   > 一部分提交了事务，一部分未提交，导致事务无法回滚。产生数据不一致问题。

   
- **3PC协议**

![1754645818202.png](https://fastly.jsdelivr.net/gh/thecoolboyhan/th_blogs@main/image/2025-08/1754645818202_1754645818239.png)



三段式提交对单点问题和回滚时的性能问题有所改善，但是它对一致性风险问题并未有任何改进，在这方面它面临的风险甚至反而是略有增加了的。譬如，进入 PreCommit 阶段之后，协调者发出的指令不是 Ack 而是 Abort，而此时因网络问题，有部分参与者直至超时都未能收到协调者的 Abort 指令的话，这些参与者将会错误地提交事务，这就产生了不同参与者之间数据不一致的问题。





#### 共享事务

> 多个服务共用同一个数据源。伪需求，不应当存在的场景

使用一个公共的交易服务器来与数据库连接，无论上游有多少个不同的服务器，都需要请求交易服务器来实现数据库操作。从而达到共享事务的效果。（但使原本分散的负载又重新聚合了）

![1754882685058.png](https://fastly.jsdelivr.net/gh/thecoolboyhan/th_blogs@main/image/2025-08/1754882685058_1754882685070.png)

> 将多个服务的事务，通过聚合到一个服务代理，转换成一个本地事务





使用消息队列让多个服务来处理任务也算是共享事务的一个变种



#### 分布式事务

> 多个服务同时访问多个数据源的事务处理机制，在分布式创建下的事务处理机制。



- CAP



![img](https://icyfenix.cn/assets/img/cap.290d0a22.png)



1. 一致性（C）：数据在任何时刻、任何分布式节点中所看到的都是符合逾期的。
2. 可用性（A）：系统不间断地提供服务的能力。
   1. 可靠性：根据平均无故障时间来度量
   2. 可维护性：平均可修复时间来度量
3. 分区容错性（P）：分布式环境中，部分节点因网络原因而彼此失联后，与其他节点形成网络分区，系统仍能正确地提供服务的能力。



> 如何取舍CAP





- **如果放弃分区容错性（CA）**：所有节点之间的通讯永远都是可靠的。（永远可靠的通讯在分布式场景下必定不存在）

- **如果放弃可用性（CP）**：一旦网络发生了分区，节点之间的信息同步可以无限制的延长。类似于前面的全局事务一致性问题，可以通过2PC/3PC手段，来获得分区容错性和一致性。

  **CP下系统一般用于对数据质量要求很高的场景中。如果发生错误，服务就下线，不再提供服务，等待恢复后才提供服务。**

- **如果放弃一致性（AP）**：一旦发生分区，节点之间提供的数据可能不一致。（目前分布式系统的主流选择）

  **高可用一般是一个分布式系统建立的主要目的，如果为了保证一致性而放弃高可用，那不如不做分布式**（银行类的金融系统除外）



> 事务出现的初衷就是为了保证一致性，在AP分布式场景下，一致性反而无法得到保证。于是为了回到初衷，又提出了最终一致性的概念。

- 最终一致性：如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果。





##### 可靠事件队列（最大努力交付）

![1754891613491.png](https://fastly.jsdelivr.net/gh/thecoolboyhan/th_blogs@main/image/2025-08/1754891613491_1754891613521.png)

目前需要做三个操作，账号扣款、商家账号收款、库存商品出库。



三个操作中账号扣款最容易出现问题，其次扣库存容易出错，收款环节最不容易出现问题。





> 一般设计时把最容易出现问题的操作放在最前面，这样出现问题回滚的代价最小。



1. 扣款：先开启一个本地事务，进行扣款和写入消息操作。如果扣款成功，就在自己本地的数据库中建立一张消息表，存入一条消息，状态为：扣款已完成，出库进行中、收款进行中。

   > 如果扣款过程出现错误，就不需要进行写入消息等操作。利用一个本地事务完成最大规模的筛选。
   >
   > 扣款成功后，后面的扣减库存和收款操作没有先后顺序，可以同时进行。

2. 收款成功、扣减库存成功：把两个消息状态都修改成已完成，整个事务结束，达到最终一致性。

3. 扣减库存或收款出现网络问题：账号服务一直没有收到消息。账号服务一直重复向未响应的服务重复发送消息。（扣减库存和收款服务一定要实现幂等性）可以同每个事务唯一的事务ID来实现幂等。

4. 库存服务或收款服务无法完成工作：没有库存或者无法收款。账号服务会不断重复发送消息直到成功为止。或者人工介入处理。**通过事件队列来处理的分布式事务没有失败回滚的概念，只许成功，不许失败。**

5. 收款和库存服务都成功后，由于网络原因导致回复给账号服务的消息丢失：账号服务会不断地重复给收款和库存服务发送消息，由于已做幂等操作，收到重复消息后，收款和库存服务会再次给账号服务发送成功消息。





> TCP协议中，如果未收到ACK应答自动重新发送包的可靠性保障就属于最大努力交付。

- 缺点

1. 可靠消息会不断的重试操作，会造成大量无畏消耗。
2. 所有操作只许成功，如果必定会失败，就会无限重试。死循环。
3. 没有任何隔离性可言，可能会出现“超售”情况。每个人购买的数量都没有超过最大数量，但加起来超过了最大数量。（会导致一个事务无限重试）



##### TCC事务



> Try-Confirm-Cancel，如果事务需要隔离性，应重点考虑TCC。但对业务入侵性较强。



1. Try：尝试执行阶段，完成所有业务可执行性的检查（保证一致性），并且预留好全部需要用到的业务资源（保证隔离性）。
2. Confirm：确认执行阶段，不进行任何业务检查，直接使用Try阶段准备的资源来完成业务处理。Confirm阶段可能会重复执行，此阶段需要做幂等性校验。
3. Cancel：取消执行阶段，释放Try阶段预留的业务资源。Cancel阶段可能会重复执行，需要幂等性。

![1754900636872.png](https://fastly.jsdelivr.net/gh/thecoolboyhan/th_blogs@main/image/2025-08/1754900636872_1754900636908.png)





业务场景与上方相同：



1. 创建事务，生成事务ID，记录到日志表中，进入Try阶段（一下所有服务调用没有先后顺序）：
   1. 用户服务：检查业务可行性，可行，将用户100元设置为冻结状态，（占用额度），通知下一步进入Confirm阶段；不可行，通知下一步进入Cancel阶段。
   2. 仓库服务：检查可行性，可行，冻结库存1（占用），通知下一步进入Confirm阶段；不可行，通知下一步进入Cancel阶段
   3. 商家服务：检查业务可行性，不需要冻结资源。
2. 如果所有业务都可行，进入Confirm阶段：
   1. 用户服务：完成操作。进行扣款。
   2. 仓库服务：按冻结数量扣减库存。
   3. 商家服务：收款。
3. 全部完成后，事务正式结束，如果2中任意步骤出现异常，都需要重新执行Confirm操作，进行最大努力交付。
4. 如果1中业务任意不可行，或任意一个服务超时，则将活动日志置为Cancel，进入Cancel阶段：
   1. 用户服务：取消业务，释放冻结的100元
   2. 仓库服务：取消业务，释放冻结的库存
   3. 商家服务：取消业务，（大哭一场，然后安慰商家谋生不易:-)）
5. 如果4全部成功，事务最终置为失败，如果4中任意操作出现异常，就重复发送Concel操作，进行最大努力交付。





- 优点



> TCC与2PC逻辑类似，但TCC所有的操作都只操作预留的资源（预冻结或占用的资源），天生具有隔离性，几乎不涉及锁和资源的争用，拥有更好的性能。



- 缺点

开发成本高，对业务的侵入性较大，更大的更换成本。



> 推荐使用阿里开源的[Seata](https://seata.io/zh-cn/)来减少TCC代码开发的编码工作量。





##### SAGA事务（一长串事件、长篇故事）



> 用来提升长时间事务运作效率的方法。避免大事务长时间锁定数据库的资源，将大事务分解成一系列本地事务的设计模式。
>
> 性能最好，适用于无法使用Try阶段的事务，如目前盛行的网络支付，直接从银行转账等类似场景。（无法进行冻结、占用等操作）







- 大事务拆分成若干小事务，
